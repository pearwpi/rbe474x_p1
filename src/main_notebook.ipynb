{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593eb79b",
   "metadata": {},
   "source": [
    "# P1: Nifty Neural Networks!\n",
    "\n",
    "\n",
    "## Table Of Content\n",
    "\n",
    "1. Introduction\n",
    "2. Preliminaries\n",
    "3. Software Setup\n",
    "4. Implementation\n",
    "5. Grading Rubric\n",
    "6. Report guidelines\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Neural networks, at their core, function like any other mathematical function that can be evaluated. The process of evaluating a neural network is referred to as the forward pass. During this step, inputs are passed through the network layers, and outputs are generated.\n",
    "\n",
    "To optimize the network's performance, its weights and biases need to be adjusted. This is done through a process called backward propagation (or backpropagation). In this step, the gradients of the loss function with respect to each parameter are calculated, and these gradients are subtracted from the corresponding weights and biases, allowing the network to learn and improve its predictions.\n",
    "\n",
    "In this assignment, you will dive into the implementation of custom layers in PyTorch. Specifically, you will focus on coding the forward pass and computing the gradients necessary for the backward pass. Before you begin, make sure to review the grading rubric to understand the criteria for evaluation.\n",
    "\n",
    "## 2. Preliminaries\n",
    "\n",
    "### CIFAR10 Dataset\n",
    "\n",
    "CIFAR-10 is a dataset consisting of 60000, 32Ã—32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. More details about the datset can be found [here](http://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "Sample images from each class of the CIFAR-10 dataset is shown below:\n",
    "\n",
    "![CIFAR 10](./artifacts/cifar10.png)\n",
    "\n",
    "In this project, you will classify images into these 10 classes using the provided pipeline,loaders and helper classes.\n",
    "\n",
    "Additionally, you are expected to generate a confusion matrix to evaluate your model's performance. For guidance on plotting a confusion matrix in PyTorch, please refer to this [resource](https://stackoverflow.com/questions/74020233/how-to-plot-confusion-matrix-in-pytorch).\n",
    "\n",
    "### Linear Layer\n",
    "A linear layer in a neural network performs a linear transformation of the input data. It is defined by the following components:\n",
    "\n",
    "1. Weights\n",
    "2. Biases\n",
    "\n",
    "More details below,\n",
    "\n",
    "[Pytorch Linear Layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
    "\n",
    "You can find information about the dimension of weights and biases in custom_layers.py\n",
    "\n",
    "### Soft Max\n",
    "The Softmax function is commonly used in neural networks for multi-class classification problems. It converts a vector of raw scores (logits) into probabilities, making it possible to interpret the output as the likelihood of each class.\n",
    "\n",
    "[Sample implementation](https://stackoverflow.com/questions/34968722/how-to-implement-the-softmax-function-in-python)\n",
    "\n",
    "More details [here](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html).\n",
    "\n",
    "### Convolutional Layer\n",
    "\n",
    "A convolutional layer is a fundamental building block in Convolutional Neural Networks (CNNs) used primarily for processing grid-like data such as images. It applies convolution operations to detect local features in the input.\n",
    "\n",
    "Although it is called a convolutional layer, the PyTorch implementation of conv2d does not actually perform a convolution in the mathematical sense. Instead, it performs a cross-correlation operation, where the kernel is not flipped. This distinction is important to note, but for most practical purposes, including this project, the difference between convolution and cross-correlation is negligible.\n",
    "\n",
    "For more details, refer to [P0](https://rbe549.github.io/rbe474x/fall2024a/proj/p0/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f305e",
   "metadata": {},
   "source": [
    "## 3. Software Setup\n",
    "\n",
    "Use a code editor like VSCode and open this entire folder.\n",
    "\n",
    "For each part, you will be implementing the corresponding layers in custom_layers.py\n",
    "\n",
    "The code will automatically be tested with test.py. \n",
    "\n",
    "To run the test, open a terminal in the current folder and run,\n",
    "\n",
    "`pytest -s -v test.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c586079",
   "metadata": {},
   "source": [
    "## 4. Implementation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d925fff4",
   "metadata": {},
   "source": [
    "### Part1 : Implement Your Custom Layers for Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb96b9",
   "metadata": {},
   "source": [
    "Open custom_layers.py and implement a fully connected, relu and softmax layer.\n",
    "\n",
    "Verify it by running the below code. Feel free to modify the below snippet. But do not modify my test.py\n",
    "\n",
    "For more information about supplying gradients, please refer to [examples_autograd](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bc90238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:custom_layers:grad_output: torch.Size([2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear\n",
      "torch.Size([1, 2])\n",
      "Inference for linear layer\n",
      "tensor([[-1.9271,  1.5348]], grad_fn=<CustomLinearLayerBackward>)\n",
      "tensor([[-1.9271,  1.5348]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "graidents for linear layer\n",
      "tensor([[-1.6524, -1.6664, -0.4797, -0.8206, -1.7842, -0.3676, -0.9836, -1.4195,\n",
      "         -1.8116, -1.0802],\n",
      "        [ 1.3160,  1.3272,  0.3820,  0.6535,  1.4210,  0.2927,  0.7834,  1.1305,\n",
      "          1.4428,  0.8603]])\n",
      "tensor([[-1.6524, -1.6664, -0.4797, -0.8206, -1.7842, -0.3676, -0.9836, -1.4195,\n",
      "         -1.8116, -1.0802],\n",
      "        [ 1.3160,  1.3272,  0.3820,  0.6535,  1.4210,  0.2927,  0.7834,  1.1305,\n",
      "          1.4428,  0.8603]])\n",
      "tensor([-1.9271,  1.5348])\n",
      "tensor([-1.9271,  1.5348])\n",
      "\n",
      "RELU\n",
      "inference\n",
      "tensor([[0.4807, 0.6850, 0.0734, 0.4227, 0.4590, 0.3284, 0.9339, 0.7052, 0.1709,\n",
      "         0.4962]], grad_fn=<CustomReLULayerBackward>) tensor([[0.4807, 0.6850, 0.0734, 0.4227, 0.4590, 0.3284, 0.9339, 0.7052, 0.1709,\n",
      "         0.4962]], grad_fn=<ReluBackward0>)\n",
      "gradients of loss relative to the input\n",
      "tensor([[0.0961, 0.1370, 0.0147, 0.0845, 0.0918, 0.0657, 0.1868, 0.1410, 0.0342,\n",
      "         0.0992]])\n",
      "tensor([[0.0961, 0.1370, 0.0147, 0.0845, 0.0918, 0.0657, 0.1868, 0.1410, 0.0342,\n",
      "         0.0992]])\n",
      "\n",
      " SoftMax\n",
      "tensor([[0.2217, 0.5213, 0.2570]], grad_fn=<CustomSoftmaxLayerBackward>)\n",
      "gradients of loss relative to the input\n",
      "tensor([[-0.0244,  0.0467, -0.0223]])\n",
      "tensor([[-0.0244,  0.0467, -0.0223]])\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import networks as net\n",
    "importlib.reload(net)\n",
    "\n",
    "print(\"\\nLinear\")\n",
    "u = torch.rand((1, 10))\n",
    "customLayer = net.CustomLinear(10, 2)\n",
    "inbuiltLayer = nn.Linear(in_features=10, out_features=2)\n",
    "\n",
    "inbuiltLayer.weight.data.copy_(customLayer.weight.data)\n",
    "inbuiltLayer.bias.data.copy_(customLayer.bias.data)\n",
    "\n",
    "y_custom = customLayer(u)\n",
    "y_inbuilt = inbuiltLayer(u)\n",
    "print(\"Inference for linear layer\")\n",
    "print(y_custom)\n",
    "print(y_inbuilt)\n",
    "\n",
    "lossFunc = nn.MSELoss()\n",
    "\n",
    "loss_custom = lossFunc(y_custom, torch.zeros_like(y_custom))\n",
    "loss_in = lossFunc(y_inbuilt, torch.zeros_like(y_inbuilt))\n",
    "\n",
    "loss_custom.backward()\n",
    "loss_in.backward()\n",
    "\n",
    "print(\"\\ngraidents for linear layer\")\n",
    "print(customLayer.weight.grad)\n",
    "print(inbuiltLayer.weight.grad)\n",
    "\n",
    "print(customLayer.bias.grad)\n",
    "print(inbuiltLayer.bias.grad)\n",
    "\n",
    "# RELU\n",
    "print(\"\\nRELU\")\n",
    "u1 = torch.rand((1, 10), requires_grad=True)\n",
    "u2 = u1.detach().clone()\n",
    "u2.requires_grad_()\n",
    "\n",
    "customLayer = net.CustomReLU()\n",
    "inbuiltLayer = nn.ReLU()\n",
    "\n",
    "y_custom = customLayer(u1)\n",
    "y_inbuilt = inbuiltLayer(u2)\n",
    "\n",
    "loss_custom = lossFunc(y_custom, torch.zeros_like(y_custom))\n",
    "loss_in = lossFunc(y_inbuilt, torch.zeros_like(y_inbuilt))\n",
    "\n",
    "loss_custom.backward()\n",
    "loss_in.backward()\n",
    "\n",
    "print(\"inference\")\n",
    "print(y_custom, y_inbuilt)\n",
    "\n",
    "print(\"gradients of loss relative to the input\")\n",
    "print(u1.grad)\n",
    "print(u2.grad)\n",
    "\n",
    "# SOFTMAX\n",
    "print(\"\\n SoftMax\")\n",
    "\n",
    "u1 = torch.rand((1, 3), requires_grad=True)\n",
    "u2 = u1.detach().clone()\n",
    "u2.requires_grad_()\n",
    "customLayer = net.CustomSoftmax(1)\n",
    "inbuiltLayer = nn.Softmax()\n",
    "\n",
    "y_custom = customLayer(u1)\n",
    "y_inbuilt = inbuiltLayer(u2)\n",
    "\n",
    "print(y_custom)\n",
    "\n",
    "loss_custom = lossFunc(y_custom, torch.zeros_like(y_custom))\n",
    "loss_in = lossFunc(y_inbuilt, torch.zeros_like(y_inbuilt))\n",
    "\n",
    "loss_custom.backward()\n",
    "loss_in.backward()\n",
    "\n",
    "print(\"gradients of loss relative to the input\")\n",
    "print(u1.grad)\n",
    "print(u2.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb0ae69",
   "metadata": {},
   "source": [
    "### Part 2: MLP Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d10d7c7",
   "metadata": {},
   "source": [
    "Now that you have implemented an MLP from scratch, it's time to train it and verify its ability to classify objects. This network is expected to achieve an accuracy of approximately 40%.\n",
    "\n",
    "Additionally, you are required to save one of your best model checkpoints as mlp.pth in the current folder. This file will be used for automated testing.\n",
    "\n",
    "Furthermore, please implement a confusion matrix in the utils file, specifically within the val_step method of the Pipeline class. You may use any available implementation of the confusion matrix, but ensure that all tests continue to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8da3018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "0 3401.538760781288 31.25\n",
      "1 3332.542497396469 33.27\n",
      "2 3302.2311228513718 35.17\n",
      "3 3271.1365426778793 36.12\n",
      "4 3245.7909129858017 37.41\n",
      "5 3224.2194608449936 37.93\n",
      "6 3204.238774418831 38.9\n",
      "7 3185.1119142770767 39.23\n",
      "8 3167.1109541654587 39.44\n",
      "9 3151.022267460823 40.08\n",
      "10 3134.811555981636 40.83\n",
      "11 3119.8740861415863 41.11\n",
      "12 3106.6075176000595 41.43\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m valAccList \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eIndex \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# print(\"Epoch count: \", eIndex)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     train_epochloss \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mval_step(model)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(eIndex, train_epochloss, val_acc)\n",
      "File \u001b[0;32m~/Dropbox/work/courses/FALL24/DL_CV/p1_sol/utils.py:44\u001b[0m, in \u001b[0;36mPipeline.train_step\u001b[0;34m(self, model, optimizer)\u001b[0m\n\u001b[1;32m     41\u001b[0m y \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlossFunc(y, labels)     \n\u001b[0;32m---> 44\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m epochloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lets train a CIFAR10 image classifier\n",
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import networks as net\n",
    "import os\n",
    "importlib.reload(net)\n",
    "\n",
    "pipeline = net.Pipeline()\n",
    "model = net.CustomMLP().to(pipeline.device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "home_path = os.path.expanduser(\"~\")\n",
    "JOB_FOLDER=os.path.join(home_path, \"outputs/\")\n",
    "TRAINED_MDL_PATH = os.path.join(JOB_FOLDER, \"cifar/mlp/\")\n",
    "\n",
    "import os\n",
    "os.makedirs(JOB_FOLDER, exist_ok=True)\n",
    "os.makedirs(TRAINED_MDL_PATH, exist_ok=True)\n",
    "\n",
    "epochs = 40\n",
    "trainLossList = []\n",
    "valAccList = []\n",
    "for eIndex in range(epochs):\n",
    "    # print(\"Epoch count: \", eIndex)\n",
    "    \n",
    "    train_epochloss = pipeline.train_step(model, optimizer)\n",
    "    val_acc = pipeline.val_step(model)\n",
    "\n",
    "    print(eIndex, train_epochloss, val_acc)\n",
    "\n",
    "    valAccList.append(val_acc)\n",
    "    trainLossList.append(train_epochloss)\n",
    "\n",
    "    trainedMdlPath = TRAINED_MDL_PATH + f\"{eIndex}.pth\"\n",
    "    torch.save(model.state_dict(), trainedMdlPath)\n",
    "\n",
    "trainLosses = np.array(trainLossList)\n",
    "testAccuracies = np.array(valAccList)\n",
    "\n",
    "np.savetxt(\"train.log\", trainLosses)\n",
    "np.savetxt(\"test.log\", testAccuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b1e2d",
   "metadata": {},
   "source": [
    "### Part 3: Implement Convolutional Neural Networks (CNN) Using PyTorch layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37c6b38",
   "metadata": {},
   "source": [
    "CNNs excel in capturing local patterns and spatial hierarchies through convolutional filters, which makes them more effective for image and spatial data. They also use parameter sharing, reducing the number of parameters and computational cost compared to MLPs. Additionally, CNNs offer translation invariance and hierarchical feature learning, enabling them to recognize features across different spatial locations and build complex patterns efficiently.\n",
    "\n",
    "Open networks.py and implement `RefCNN` using the inbuilt layers in pytorch. Make sure it is similar to CustomCNN() which uses custom layers.\n",
    "\n",
    "Train and compare the train loss and validation accuracy against MLP. \n",
    "\n",
    "Please copy the best checkpoint file in current folder as cnn_inbuilt.pth for automated tests. It is expected to be higher than 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9a9cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "train complete\n",
      "0 3395.6308230161667 32.71\n",
      "train complete\n",
      "1 3306.9195926189423 36.02\n",
      "train complete\n",
      "2 3261.761631965637 37.95\n",
      "train complete\n",
      "3 3228.619769215584 40.44\n",
      "train complete\n",
      "4 3192.552641272545 41.66\n",
      "train complete\n",
      "5 3160.2860820293427 42.08\n",
      "train complete\n",
      "6 3129.7814899683 45.51\n",
      "train complete\n",
      "7 3102.0351588726044 45.64\n",
      "train complete\n",
      "8 3076.8622094392776 47.42\n",
      "train complete\n",
      "9 3053.5578776597977 46.56\n",
      "train complete\n",
      "10 3031.7073751688004 49.19\n",
      "train complete\n",
      "11 3012.578893184662 49.13\n",
      "train complete\n",
      "12 2993.0348378419876 49.07\n",
      "train complete\n",
      "13 2974.839825630188 50.92\n",
      "train complete\n",
      "14 2956.0333145856857 51.78\n",
      "train complete\n",
      "15 2938.5095987319946 52.03\n",
      "train complete\n",
      "16 2919.018166780472 52.42\n",
      "train complete\n",
      "17 2900.8069647550583 52.86\n",
      "train complete\n",
      "18 2882.187391281128 53.64\n",
      "train complete\n",
      "19 2865.9195289611816 53.65\n",
      "train complete\n",
      "20 2847.7179921865463 54.14\n",
      "train complete\n",
      "21 2832.156553506851 54.64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m valAccList \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eIndex \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# print(\"Epoch count: \", eIndex)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     train_epochloss \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mval_step(model)\n",
      "File \u001b[0;32m~/Dropbox/work/courses/FALL24/DL_CV/p1_sol/utils.py:32\u001b[0m, in \u001b[0;36mPipeline.train_step\u001b[0;34m(self, model, optimizer)\u001b[0m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     31\u001b[0m epochloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batchcount, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainloader):\n\u001b[1;32m     33\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     34\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/multiprocessing/queues.py:116\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py:355\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[0;32m--> 355\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m         storage \u001b[38;5;241m=\u001b[39m storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction\u001b[38;5;241m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/multiprocessing/resource_sharer.py:87\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     86\u001b[0m address, key \u001b[38;5;241m=\u001b[39m ident\n\u001b[0;32m---> 87\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m c\u001b[38;5;241m.\u001b[39msend((key, os\u001b[38;5;241m.\u001b[39mgetpid()))\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/multiprocessing/connection.py:508\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthkey should be a byte string\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m     \u001b[43manswer_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m     deliver_challenge(c, authkey)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/multiprocessing/connection.py:752\u001b[0m, in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(authkey, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthkey must be bytes, not \u001b[39m\u001b[38;5;132;01m{0!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(authkey)))\n\u001b[0;32m--> 752\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m message[:\u001b[38;5;28mlen\u001b[39m(CHALLENGE)] \u001b[38;5;241m==\u001b[39m CHALLENGE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage = \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m message\n\u001b[1;32m    754\u001b[0m message \u001b[38;5;241m=\u001b[39m message[\u001b[38;5;28mlen\u001b[39m(CHALLENGE):]\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lets train a CIFAR10 image classifier\n",
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import networks as net\n",
    "import os\n",
    "importlib.reload(net)\n",
    "\n",
    "pipeline = net.Pipeline()\n",
    "model = net.RefCNN().to(pipeline.device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "home_path = os.path.expanduser(\"~\")\n",
    "JOB_FOLDER=os.path.join(home_path, \"outputs/\")\n",
    "TRAINED_MDL_PATH = os.path.join(JOB_FOLDER, \"cifar/cnn_inbuilt_layers/\")\n",
    "\n",
    "import os\n",
    "os.makedirs(JOB_FOLDER, exist_ok=True)\n",
    "os.makedirs(TRAINED_MDL_PATH, exist_ok=True)\n",
    "\n",
    "epochs = 40\n",
    "trainLossList = []\n",
    "valAccList = []\n",
    "for eIndex in range(epochs):\n",
    "    # print(\"Epoch count: \", eIndex)\n",
    "    \n",
    "    train_epochloss = pipeline.train_step(model, optimizer)\n",
    "    print(\"train complete\")\n",
    "    val_acc = pipeline.val_step(model)\n",
    "\n",
    "    print(eIndex, train_epochloss, val_acc)\n",
    "\n",
    "    valAccList.append(val_acc)\n",
    "    trainLossList.append(train_epochloss)\n",
    "\n",
    "    trainedMdlPath = TRAINED_MDL_PATH + f\"{eIndex}.pth\"\n",
    "    torch.save(model.state_dict(), trainedMdlPath)\n",
    "\n",
    "trainLosses = np.array(trainLossList)\n",
    "testAccuracies = np.array(valAccList)\n",
    "\n",
    "np.savetxt(\"train.log\", trainLosses)\n",
    "np.savetxt(\"test.log\", testAccuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b9224",
   "metadata": {},
   "source": [
    "### Part 4: Implement Your Custom Layers for Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e78b4fe",
   "metadata": {},
   "source": [
    "Open custom_layers.py and implement the CustomConvLayer.\n",
    "\n",
    "Verify it by running the below code. Feel free to modify the below snippet. But do not modify my test.py\n",
    "\n",
    "For more information about supplying gradients, please refer to [examples_autograd](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23dc62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv. Inference\n",
      "tensor([[[[ 3.0292,  2.5907],\n",
      "          [ 1.9953,  2.2171]],\n",
      "\n",
      "         [[-3.2437, -4.0844],\n",
      "          [-4.5176, -2.8127]],\n",
      "\n",
      "         [[ 2.6649,  4.0459],\n",
      "          [ 2.4324,  2.7375]]]], grad_fn=<ConvolutionBackward0>)\n",
      "tensor([[[[ 3.0292,  2.5907],\n",
      "          [ 1.9953,  2.2171]],\n",
      "\n",
      "         [[-3.2437, -4.0844],\n",
      "          [-4.5176, -2.8127]],\n",
      "\n",
      "         [[ 2.6649,  4.0459],\n",
      "          [ 2.4324,  2.7375]]]], grad_fn=<CustomConvLayerBackward>)\n",
      "torch.Size([1, 3, 2, 2])\n",
      "gradients of loss relative to the weights\n",
      "tensor([[[[ 0.7114,  0.9178,  0.9775],\n",
      "          [ 0.9442,  0.2337,  0.9777],\n",
      "          [ 0.4943,  0.6510,  0.8789]],\n",
      "\n",
      "         [[ 0.9618,  1.1395,  1.1611],\n",
      "          [ 1.0613,  0.6871,  1.1667],\n",
      "          [ 0.9276,  0.8520,  0.8260]]],\n",
      "\n",
      "\n",
      "        [[[-0.9761, -1.2611, -1.3281],\n",
      "          [-1.5461, -0.3333, -1.4937],\n",
      "          [-0.8250, -1.1187, -1.3356]],\n",
      "\n",
      "         [[-1.4588, -1.7792, -1.6263],\n",
      "          [-1.5367, -1.2497, -1.7598],\n",
      "          [-1.4386, -1.0886, -1.2960]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8703,  1.1050,  1.1746],\n",
      "          [ 1.2143,  0.2371,  1.1249],\n",
      "          [ 0.6155,  0.7725,  1.1508]],\n",
      "\n",
      "         [[ 1.2511,  1.4225,  1.3374],\n",
      "          [ 1.3632,  0.8839,  1.3910],\n",
      "          [ 1.1352,  0.9623,  1.0187]]]])\n",
      "tensor([[[[ 0.7114,  0.9178,  0.9775],\n",
      "          [ 0.9442,  0.2337,  0.9777],\n",
      "          [ 0.4943,  0.6510,  0.8789]],\n",
      "\n",
      "         [[ 0.9618,  1.1395,  1.1611],\n",
      "          [ 1.0613,  0.6871,  1.1667],\n",
      "          [ 0.9276,  0.8520,  0.8260]]],\n",
      "\n",
      "\n",
      "        [[[-0.9761, -1.2611, -1.3281],\n",
      "          [-1.5461, -0.3333, -1.4937],\n",
      "          [-0.8250, -1.1187, -1.3356]],\n",
      "\n",
      "         [[-1.4588, -1.7792, -1.6263],\n",
      "          [-1.5367, -1.2497, -1.7598],\n",
      "          [-1.4386, -1.0886, -1.2960]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8703,  1.1050,  1.1746],\n",
      "          [ 1.2143,  0.2371,  1.1249],\n",
      "          [ 0.6155,  0.7725,  1.1508]],\n",
      "\n",
      "         [[ 1.2511,  1.4225,  1.3374],\n",
      "          [ 1.3632,  0.8839,  1.3910],\n",
      "          [ 1.1352,  0.9623,  1.0187]]]])\n",
      "gradients of loss relative to the bias\n",
      "tensor([ 1.6387, -2.4431,  1.9801])\n",
      "tensor([ 1.6387, -2.4431,  1.9801])\n",
      "gradients of loss relative to the input\n",
      "tensor([[[[-0.3167,  0.8961, -1.0814,  1.1905, -0.2681],\n",
      "          [ 0.2148, -1.3430, -0.1367, -1.6110, -0.5789],\n",
      "          [-2.0314,  1.1864,  0.1971,  1.5048,  2.3474],\n",
      "          [ 0.1399, -1.2127, -0.4238, -1.1773, -0.2514],\n",
      "          [-0.6962,  0.2707,  1.4599,  0.4120,  1.7503]],\n",
      "\n",
      "         [[-0.6306, -0.1712,  0.8836, -0.2578,  1.7443],\n",
      "          [ 0.1569,  0.2673,  0.8295,  0.3499,  1.0082],\n",
      "          [ 0.2843, -1.0575,  3.1905, -0.7623,  2.3867],\n",
      "          [-0.1168,  0.5107,  1.5428,  0.2274,  0.6673],\n",
      "          [ 1.3627, -0.5451,  1.5577, -0.4381,  0.7982]]]])\n",
      "tensor([[[[-0.3167,  0.8961, -1.0814,  1.1905, -0.2681],\n",
      "          [ 0.2148, -1.3430, -0.1367, -1.6110, -0.5789],\n",
      "          [-2.0314,  1.1864,  0.1971,  1.5048,  2.3474],\n",
      "          [ 0.1399, -1.2127, -0.4238, -1.1773, -0.2514],\n",
      "          [-0.6962,  0.2707,  1.4599,  0.4120,  1.7503]],\n",
      "\n",
      "         [[-0.6306, -0.1712,  0.8836, -0.2578,  1.7443],\n",
      "          [ 0.1569,  0.2673,  0.8295,  0.3499,  1.0082],\n",
      "          [ 0.2843, -1.0575,  3.1905, -0.7623,  2.3867],\n",
      "          [-0.1168,  0.5107,  1.5428,  0.2274,  0.6673],\n",
      "          [ 1.3627, -0.5451,  1.5577, -0.4381,  0.7982]]]])\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import networks as net\n",
    "import os\n",
    "importlib.reload(net)\n",
    "\n",
    "inbuiltLayer = nn.Conv2d(2, 3, 3, stride=2, padding='valid')\n",
    "customLayer = net.CustomConv2d(2, 3, 3, 2)\n",
    "\n",
    "inbuiltLayer.weight.data.copy_(customLayer.weight.data)\n",
    "inbuiltLayer.bias.data.copy_(customLayer.bias.data)\n",
    "\n",
    "u1 = torch.rand((1, 2, 5, 5), requires_grad=True)\n",
    "u2 = u1.detach().clone()\n",
    "u2.requires_grad_()\n",
    "\n",
    "y1 = inbuiltLayer(u1)\n",
    "y2 = customLayer(u2)\n",
    "\n",
    "print(\"Conv. Inference\")\n",
    "print(y1)\n",
    "print(y2)\n",
    "\n",
    "lossFunc = nn.MSELoss()\n",
    "loss_custom = lossFunc(y2, torch.zeros_like(y2))\n",
    "loss_in = lossFunc(y1, torch.zeros_like(y1))\n",
    "\n",
    "loss_in.backward()\n",
    "loss_custom.backward()\n",
    "\n",
    "print(\"gradients of loss relative to the weights\")\n",
    "print(inbuiltLayer.weight.grad)\n",
    "print(customLayer.weight.grad)\n",
    "\n",
    "print(\"gradients of loss relative to the bias\")\n",
    "print(inbuiltLayer.bias.grad)\n",
    "print(customLayer.bias.grad)\n",
    "\n",
    "print(\"gradients of loss relative to the input\")\n",
    "print(u1.grad)\n",
    "print(u2.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf028b78",
   "metadata": {},
   "source": [
    "### Part 5: CNN Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ca731",
   "metadata": {},
   "source": [
    "Train and compare the train loss and validation accuracy against MLP and inbuilt conv layers. \n",
    "\n",
    "Please copy the best checkpoint file in current folder as `cnn_custom.pth` for automated tests. It is expected to be higher than 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f31b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m valAccList \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eIndex \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# print(\"Epoch count: \", eIndex)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     train_epochloss \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mval_step(model)\n",
      "File \u001b[0;32m~/Dropbox/work/courses/FALL24/DL_CV/p1_sol/utils.py:44\u001b[0m, in \u001b[0;36mPipeline.train_step\u001b[0;34m(self, model, optimizer)\u001b[0m\n\u001b[1;32m     41\u001b[0m y \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlossFunc(y, labels)     \n\u001b[0;32m---> 44\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m epochloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lets train a CIFAR10 image classifier\n",
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import networks as net\n",
    "import os\n",
    "importlib.reload(net)\n",
    "\n",
    "pipeline = net.Pipeline()\n",
    "model = net.CustomCNN().to(pipeline.device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "home_path = os.path.expanduser(\"~\")\n",
    "JOB_FOLDER=os.path.join(home_path, \"outputs/\")\n",
    "TRAINED_MDL_PATH = os.path.join(JOB_FOLDER, \"cifar/cnn_custom_layer/\")\n",
    "\n",
    "import os\n",
    "os.makedirs(JOB_FOLDER, exist_ok=True)\n",
    "os.makedirs(TRAINED_MDL_PATH, exist_ok=True)\n",
    "\n",
    "epochs = 40\n",
    "trainLossList = []\n",
    "valAccList = []\n",
    "for eIndex in range(epochs):\n",
    "    # print(\"Epoch count: \", eIndex)\n",
    "    \n",
    "    train_epochloss = pipeline.train_step(model, optimizer)\n",
    "    print(\"train complete\")\n",
    "    val_acc = pipeline.val_step(model)\n",
    "\n",
    "    print(eIndex, train_epochloss, val_acc)\n",
    "\n",
    "    valAccList.append(val_acc)\n",
    "    trainLossList.append(train_epochloss)\n",
    "\n",
    "    trainedMdlPath = TRAINED_MDL_PATH + f\"{eIndex}.pth\"\n",
    "    torch.save(model.state_dict(), trainedMdlPath)\n",
    "\n",
    "trainLosses = np.array(trainLossList)\n",
    "testAccuracies = np.array(valAccList)\n",
    "\n",
    "np.savetxt(\"train.log\", trainLosses)\n",
    "np.savetxt(\"test.log\", testAccuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54272187",
   "metadata": {},
   "source": [
    "## 5. Grading Rubric\n",
    "\n",
    "- part 1 : 60\n",
    "- part 2 : 10\n",
    "- part 3 : 10\n",
    "- part 4 : 10\n",
    "- part 5 : 10\n",
    "\n",
    "- For RBE474X: part1 + part2 + part3 = 100% of the grade (80/80).\n",
    "- For RBE595-A01-SP: You are expected to implement part1-part5 for getting full credits (100/100).\n",
    "\n",
    "Your code will be evaluated with test.py. Please run it and ensure that the tests pass before submitting. Instructions are in software setup section.\n",
    "\n",
    "Please note that I will replace the test.py with my original test.py before evaluating.\n",
    "\n",
    "Please do not submit the data folder that is downloaded while training the network. It is over 300 MB. Anyone submitting data will be penalized! Your submission should not be more than 20 MB.\n",
    "\n",
    "## 6. Report Guidelines\n",
    "\n",
    "Report must be in Latex.\n",
    "\n",
    "Include the following,\n",
    "\n",
    "1. Training loss curve (loss vs epoch count)\n",
    "2. Confusion Matrix for validation set (val_step)\n",
    "3. Accuracy comparison between MLP, CNN (torch layers) and CNN (custom_layers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
